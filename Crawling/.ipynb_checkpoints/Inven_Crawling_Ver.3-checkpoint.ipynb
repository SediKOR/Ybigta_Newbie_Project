{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e085998",
   "metadata": {},
   "source": [
    "주의 사항\n",
    "1) selenium driver 업데이트 권장드립니다 -> !pip install selenium --upgrade  \n",
    "2) 크롬창 우측 상단 점 3개 클릭 - 도움말 - chrome 정보에서 chrome 버전 확인하시고 거기에 맞는 웹드라이버 사용 부탁드립니다.  \n",
    "3) 제가 직접 올린 웹드라이버는 1.16버전으로, 최신 1.15 크롬에서 원할하게 돌아감을 확인했습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6e114",
   "metadata": {},
   "source": [
    "pip install selenium  \n",
    "pip install request  \n",
    "pip install webdriver_manager  \n",
    "등등 필요한 라이브러리 설치 후 실행 요망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7950dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "## 웹드라이버 옵션 추가: 동적 크롤링 성능 향상을 위해 쓸데없는 옵션들 모두 제외\n",
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument(\"disable-gpu\") \n",
    "options.add_argument(\"disable-infobars\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "caps = DesiredCapabilities().CHROME\n",
    "caps[\"pageLoadStrategy\"] = \"none\"\n",
    "\n",
    "# headless 해제시에만 적용됨. 테스트 위해 추가.\n",
    "prefs = {'profile.default_content_setting_values': {'cookies' : 2, 'images': 2, 'plugins' : 2, \n",
    "                                                    'popups': 2, 'geolocation': 2, 'notifications' : 2, \n",
    "                                                    'auto_select_certificate': 2, 'fullscreen' : 2, 'mouselock' : 2, \n",
    "                                                    'mixed_script': 2, 'media_stream' : 2, 'media_stream_mic' : 2, \n",
    "                                                    'media_stream_camera': 2, 'protocol_handlers' : 2, 'ppapi_broker' : 2, \n",
    "                                                    'automatic_downloads': 2, 'midi_sysex' : 2, 'push_messaging' : 2, \n",
    "                                                    'ssl_cert_decisions': 2, 'metro_switch_to_desktop' : 2, \n",
    "                                                    'protected_media_identifier': 2, 'app_banner': 2, 'site_engagement' : 2, \n",
    "                                                    'durable_storage' : 2}}   \n",
    "options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "\n",
    "## 옵션 1: 싱글 스레드 버전.\n",
    "def crawl(url):\n",
    "\n",
    "    ## 코멘트 저장 위해 빈 리스트 생성\n",
    "    comment_list = []\n",
    "    \n",
    "    ## 정적 크롤링으로 화제글 위에서부터 10개 뽑아오기\n",
    "    html_table = requests.get(url).text\n",
    "    soup_table = bs(html_table,'html.parser')\n",
    "    data_box = soup_table.find_all('a',attrs = {'class':'subject-link'})[10:20]\n",
    "    \n",
    "    ## 드라이버 생성\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    for index, data in enumerate(data_box):\n",
    "        \n",
    "        print(index+1,\"번째 게시글에서 댓글을 추출중입니다...\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        \n",
    "        ## 데이터박스 아이템 별로 링크 뽑아서 열기\n",
    "        link = data.attrs['href']\n",
    "        driver.get(link)\n",
    "\n",
    "        try:\n",
    "            ## 코멘트 래퍼 로딩까지 기다리기\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((\n",
    "                By.XPATH,'//*[@id=\"powerbbsCmt2\"]/div[2]')))\n",
    "                \n",
    "        except TimeoutException:\n",
    "            print(\"요소가 나타나지 않았습니다.\")\n",
    "            \n",
    "        else:\n",
    "            ## Xpath 형식 동일한 댓글들 모조리 긁어오기\n",
    "            comment_box = driver.find_elements(\n",
    "                By.XPATH,'//*[starts-with(@id, \"cmt\")]/div[2]/div[2]/span')\n",
    "                \n",
    "            ## 전체 댓글에서 3개 랜덤추출 후 결과 리스트에 추가\n",
    "            selected_comments = random.sample(comment_box, 3)\n",
    "            comment_list = comment_list + [comment.text for comment in selected_comments]\n",
    "    \n",
    "    ## 드라이버 닫기\n",
    "    driver.close()\n",
    "                        \n",
    "    print(\"댓글 추출이 완료되었습니다!\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    return comment_list\n",
    "\n",
    "\"\"\"\n",
    "## 옵션 2: 멀티스레드 버전.\n",
    "def crawl_single(link):\n",
    "    print(\"게시글에서 댓글을 추출중입니다...\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.get(link)\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((\n",
    "            By.XPATH,'//*[@id=\"powerbbsCmt2\"]/div[2]')))\n",
    "    except TimeoutException:\n",
    "        print(\"요소가 나타나지 않았습니다.\")\n",
    "    else:\n",
    "        comment_box = driver.find_elements(\n",
    "            By.XPATH,'//*[starts-with(@id, \"cmt\")]/div[2]/div[2]/span')\n",
    "        selected_comments = random.sample(comment_box, 3)\n",
    "        comment_list = [comment.text for comment in selected_comments]\n",
    "        \n",
    "    driver.close()\n",
    "\n",
    "    print(\"댓글 추출이 완료되었습니다!\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    return comment_list\n",
    "\n",
    "\n",
    "def crawl(url):\n",
    "    comment_list = []\n",
    "    html_table = requests.get(url).text\n",
    "    soup_table = bs(html_table, 'html.parser')\n",
    "    data_box = soup_table.find_all('a', attrs={'class': 'subject-link'})[10:20]\n",
    "    \n",
    "    # ThreadPoolExecutor를 사용하여 병렬 처리\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        links = [data.attrs['href'] for data in data_box]\n",
    "        results = executor.map(crawl_single, links)\n",
    "        for result in results:\n",
    "            comment_list.extend(result)      \n",
    "    return comment_list\n",
    "\"\"\"\n",
    "\n",
    "def query():\n",
    "\n",
    "    while(True):\n",
    "        print(\"인벤 코드를 이용해서 검색해주세요\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        print(\"리그 오브 레전드 :              0\")\n",
    "        print(\"메이플스토리     :              1\")\n",
    "        print(\"피파온라인 4     :              2\")\n",
    "        print(\"디아블로 4       :              3\")\n",
    "        print(\"로스트아크       :              4\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "    \n",
    "        try:\n",
    "            game = int(input(\"코드 입력 \"))\n",
    "            if game < 0 or game > 4:\n",
    "                raise ValueError()\n",
    "    \n",
    "        except ValueError:\n",
    "            print(\"잘못된 입력입니다. 코드를 확인해주세요.\")\n",
    "            print(\"-------------------------------------------------------\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"알 수 없는 예외가 발생했습니다:\", e)\n",
    "            print(\"-------------------------------------------------------\")\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    ##start = time.time()\n",
    "    \n",
    "    print(\"-------------------------------------------------------\")\n",
    "    if game == 0:\n",
    "        print(\"리그 오브 레전드 인벤의 오늘의 화제글을 불러옵니다.\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        url = \"https://www.inven.co.kr/board/lol/4625?my=chuchu\"\n",
    "        result = crawl(url)\n",
    "        \n",
    "    elif game == 1:\n",
    "        print(\"메이플스토리 인벤의 30추글 목록을 불러옵니다.\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        url = \"https://www.inven.co.kr/board/maple/5974?my=chuchu\"\n",
    "        result = crawl(url)\n",
    "        \n",
    "    elif game == 2:\n",
    "        print(\"피파온라인 4 인벤의 오늘의 화제글을 불러옵니다.\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        url = \"https://www.inven.co.kr/board/fifaonline4/3146?my=chu\"\n",
    "        result = crawl(url)\n",
    "        \n",
    "    elif game == 3:\n",
    "        print(\"디아블로 4 인벤의 30추글 목록을 불러옵니다.\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        url = \"https://www.inven.co.kr/board/diablo4/6025?my=chuchu\"\n",
    "        result = crawl(url)\n",
    "        \n",
    "    elif game == 4:\n",
    "        print(\"로스트아크 인벤의 30추글 목록을 불러옵니다.\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        url = \"https://www.inven.co.kr/board/lostark/4811?my=chuchu\"\n",
    "        result = crawl(url)\n",
    "        \n",
    "    df_result = pd.DataFrame(result, columns=['comments'])\n",
    "    df_result.to_csv('C:/Users/wjdgh/Desktop/comments.csv',encoding='utf-8-sig')\n",
    "    print(\"csv파일 생성 완료.\")\n",
    "    ##end = time.time()\n",
    "    ##print(f\"{end - start:.5f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22691d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인벤 코드를 이용해서 검색해주세요\n",
      "-------------------------------------------------------\n",
      "리그 오브 레전드 :              0\n",
      "메이플스토리     :              1\n",
      "피파온라인 4     :              2\n",
      "디아블로 4       :              3\n",
      "로스트아크       :              4\n",
      "-------------------------------------------------------\n",
      "코드 입력 1\n",
      "-------------------------------------------------------\n",
      "메이플스토리 인벤의 30추글 목록을 불러옵니다.\n",
      "-------------------------------------------------------\n",
      "1 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "2 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "3 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "4 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "5 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "6 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "7 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "8 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "9 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "10 번째 게시글에서 댓글을 추출중입니다...\n",
      "-------------------------------------------------------\n",
      "댓글 추출이 완료되었습니다!\n",
      "-------------------------------------------------------\n",
      "csv파일 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "query()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
